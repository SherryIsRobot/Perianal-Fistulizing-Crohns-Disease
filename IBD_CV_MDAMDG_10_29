---
title: "IBD_CV_MDAMDG_10_29"
author: "Sherry"
date: "2024-10-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(randomForest)
library(caret)
library(DESeq2)
library(ggplot2)
```

### Import the dataset

```{r import}
cnt <- read.delim("/Users/sherrywang/Desktop/Research/Furey/AnalysisTable/RUVg_k10_normalized_counts.tsv", header=T, check.names = FALSE)
head(cnt)
met <- read.delim("/Users/sherrywang/Desktop/Research/Furey/AnalysisTable/plexus_atac_metadata_03112024.tsv", header=T)
head(met)
```

### Reshape the dataset

```{r clean}
# Rename the columns and reset the data type
mdata <- met %>%
  select(DEIDENTIFIED_MASTER_PATIENT_ID, Group) %>%
  mutate(DID = as.factor(DEIDENTIFIED_MASTER_PATIENT_ID)) %>%  
  select(-DEIDENTIFIED_MASTER_PATIENT_ID)  

mdata$Group <- as.factor(gsub("[^[:alnum:]_.]", "_", mdata$Group))

# Adding row name
rownames(cnt) <- cnt[, 1]
cdata <- cnt[, -1]

cnt_DID_COUNT <- data.frame(t(cdata))
cnt_DID_COUNT


# Optionally, remove the first row if it was used as column names
cnt_DID_COUNT$DID <- rownames(cnt_DID_COUNT)

# Join and reorder the dataset
# complete <- left_join(cnt_DID_COUNT, mdata, by = "DID")
# complete <- complete[, c(ncol(complete), 1:(ncol(complete)-1))]
# complete <- complete[, c(ncol(complete), 1:(ncol(complete)-1))]

# head(complete)

```

### Randomized group
```{r random}
set.seed(222)  # For reproducibility

# Total number of individuals
n <- nrow(met)

# Generate fold indices
folds <- cut(sample(1:n), breaks = 5, labels = FALSE)

# View the folds
folds

# Add the folds to the complete dataset
# complete$folds <- folds

# Add the folds to metadata and count data
mdata$folds <- folds
head(mdata)

```
### Loop for cross-validation

```{r loop}

# Cross_val <- function(mdata, cdata) {

  results <- list()
  
  # Perform 5-fold cross-validation
  for (i in 1:5) {
    test_index <- which(mdata$folds == i, arr.ind = TRUE)  # Get the indices for the test set
    train_mdata <- mdata[-test_index, ]  # Training set: all rows except the test set
    test_mdata  <- mdata[test_index, ] # Test set: only rows in the current fold
      
    cdata_DID <- colnames(cdata)
  
    # Find the columns in second dataset that match values in DID column from the first dataset
    match <- cdata_DID[cdata_DID %in% train_mdata$DID]
    
    # Select columns based on 'match'
    train_cdata <- cdata %>%
      select(all_of(match))
  
    # Select columns NOT in 'match'
    test_cdata <- cdata %>%
      select(-all_of(match))
  
    # DESeq2
    dds <- DESeqDataSetFromMatrix(countData = train_cdata,
                                colData = train_mdata,
                                design = ~ Group)
    dds <- DESeq(dds)
    
    # View result
    res <- results(dds)
    
    # Extract the top 1000 features
    # Subset the dataframe to include only rows where baseMean >= 100
  res_filtered <- res[res$baseMean >= 100, ]
  
  # Check if the filtered dataframe is not empty
    if (nrow(res_filtered) > 0) {
      # Extract padj and calculate rank
      padj <- res_filtered[, 6]
      rankpadj <- rank(-padj, na.last = "keep", ties.method = "average")
      
      # Add RankPAdj to the dataframe
      res_filtered$RankPAdj <- rankpadj
      
      # Order by RankPAdj and select top 1000 features
      orderP <- res_filtered[order(-res_filtered$RankPAdj), ]
      fea_select <- head(orderP, 1000)
    } else {
      # Handle case where no rows meet the condition
      fea_select <- NULL
      message("No rows with baseMean >= 100")
    }
    
    fea <- data.frame(rownames(fea_select))
    colnames(fea) <- "Feature"
    
    # Reshape Train Set
    train_cdata$Feature <- rownames(train_cdata)
    fea_cnt_train <- left_join(fea, train_cdata, by = "Feature")
    train_ana <- data.frame(t(fea_cnt_train))
    colnames(train_ana) <- train_ana[1,]
    train_ana <- train_ana[-1,]
    train_ana$DID <- rownames(train_ana)
    train_ana <- train_ana[, c(ncol(train_ana), 1:(ncol(train_ana)-1))]
    train_ana <- left_join(train_ana, mdata, by = "DID")
    train_ana <- train_ana[, c(ncol(train_ana), 1:(ncol(train_ana)-1))]
    train_ana <- train_ana[, -2]
    cols_train <- setdiff(names(train_ana), "Group")
    train_ana[cols_train] <- lapply(train_ana[cols_train], function(x) {
      if (is.factor(x)) {
        x <- as.character(x)
      }
      as.numeric(x)
    })
  
  
    # Reshape Test Set
    test_cdata$Feature <- rownames(test_cdata)
    fea_cnt_test <- left_join(fea, test_cdata, by = "Feature")
    test_ana <- data.frame(t(fea_cnt_test))
    colnames(test_ana) <- test_ana[1,]
    test_ana <- test_ana[-1,]
    test_ana$DID <- rownames(test_ana)
    test_ana <- test_ana[, c(ncol(test_ana), 1:(ncol(test_ana)-1))]
    test_ana <- left_join(test_ana, mdata, by = "DID")
    test_ana <- test_ana[, c(ncol(test_ana), 1:(ncol(test_ana)-1))]
    test_ana <- test_ana[, -2]
    cols_test <- setdiff(names(test_ana), "Group")
    test_ana[cols_test] <- lapply(test_ana[cols_test], function(x) {
      if (is.factor(x)) {
        x <- as.character(x)
      }
      as.numeric(x)
    })
  
    # Run Random Forest model
    rf <- randomForest(as.factor(Group) ~ ., data = train_ana, importance = TRUE)
    
    # Predictions
    predictions_train <- predict(rf, newdata = train_ana)
    predictions <- predict(rf, newdata = test_ana)
    
    # Model Summary
    cat(paste0("\n\nResult for Loop ", i, "\n"))
    print(rf)
    
    # Misclassified Individuals
    misclassified <- test_mdata[test_ana$Group != predictions, ]
    cat("\nMisclassified Individuals:\n")
    print(misclassified)
    
    # Accuracy for Train Dataset
    confusion_matrix_train <- table(predictions_train, train_ana$Group)
    accuracy_train <- sum(diag(confusion_matrix_train)) / sum(confusion_matrix_train)
    cat(paste("Accuracy with Train Dataset:", round(accuracy_train * 100, 2), "%\n"))
    
    # Accuracy for Test Dataset
    confusion_matrix <- table(predictions, test_ana$Group)
    accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
    cat(paste("Accuracy with Test Dataset:", round(accuracy * 100, 2), "%\n"))
    
    # Variable Importance
    importance_df <- data.frame(importance(rf))
    importance_df$RankAccuracy <- rank(importance_df$MeanDecreaseAccuracy, na.last = F, ties.method = "average")
    importance_df$RankGini <- rank(importance_df$MeanDecreaseGini, na.last = F, ties.method = "average")
    importance_df$Score <- importance_df$RankAccuracy + importance_df$RankGini
    importance_df <- importance_df[order(-importance_df$Score), ]
    
    cat("\nVariable Importance:\n")
    print(importance_df)
    
    # Plot Variable Importance
    varImpPlot(rf, sort = TRUE, n.var = min(500, nrow(importance_df)), main = paste("Random Forest Variable Importance (Fold", i, ")"))
    
    # Plot Score
    plot(importance_df$Score, main = paste("Importance Score Plot (Fold", i, ")"), ylab = "Score", xlab = "Features", type = "b")
    
    # Store results in list for further analysis if needed
    results[[i]] <- list(
      model_summary = rf,
      misclassified = misclassified,
      accuracy_train = accuracy_train,
      accuracy_test = accuracy,
      importance_df = importance_df
    )
  }
  
# }

```

```{r}
results[1]
results[2]
results[3]
results[4]
results[5]
```
